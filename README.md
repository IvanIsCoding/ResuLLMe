# ResuLLMe [![Open in Streamlit](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://resullme.streamlit.app/) [![](https://img.shields.io/github/license/IvanIsCoding/ResuLLMe)](https://github.com/IvanIsCoding/ResuLLMe/blob/main/LICENSE) ![](https://img.shields.io/badge/code%20style-black-black)

---

![](./.github/images/Preview.png)

üëâ Check some sample r√©sum√©s generated by ResuLLMe ([1](./.github/samples/Simple.pdf), [2](./.github/samples/Alta.pdf), [3](./.github/samples/Awesome.pdf))

## üöÄ Concept

ResuLLMe is a prototype that uses Large Language Models (LLMs) to tailor r√©sum√©s. It's goal is to enhance r√©sum√©s to help candidates avoid common mistakes that occur while applying for jobs. It is like a smart career advisor to check your r√©sum√©.

You can use ResuLLMe live at [https://resullme.streamlit.app/](https://resullme.streamlit.app/).

## üõ† How It Works
ResuLLMe now supports both OpenAI and Gemini, empowering the application to enhance r√©sum√©s with even more powerful and diverse language models, providing users with smarter, more accurate career guidance.  

ResuLLMe receives your previous CV as a PDF or Word Document. Then, it uses LLMs to:
* Improve the r√©sum√© following published r√©sum√© guidelines by well-reputed schools
* Convert the r√©sum√©s to a JSON Resume format
* Render the JSON resume using LaTeX to generate a new PDF of the enhanced resume

> [!IMPORTANT]  
> ResuLLMe was updated to support macOS and Windows. For that to happen, we had to switch the LaTeX engine. If you prefer the old rendering behavior, check the code in the `stable/v1` branch.

## üèÉ Running Natively


To run the app locally, you will need to install [Pixi](https://prefix.dev/):

```
curl -fsSL https://pixi.sh/install.sh | bash
```

Lastly, to run ResuLLMe locally, execute:

```
pixi run run-app
```

This will make the app avaialable at [`https://localhost:8501/`](https://localhost:8501/)

### ü™Ñ Running with Docker

To run ResuLLMe locally, the simplest way is to use Docker:

```
docker-compose up -d
```

This will make the app avaialable at [`https://localhost:8501/`](https://localhost:8501/)


## ü§≤ Contributing

ResuLLMe is an open source project.

If you want to contribute, open a [Pull requests](https://github.com/360macky/project-name/pulls). 
All contributions are welcome, but some that would particularly be useful to the community are:
* Fixes in existing LaTeX templates
* Adding new LaTeX templates
* Improved prompts
* Support for other LLMs (e.g. Bard, Claude, LLaMA)
